{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d10e638-15bd-42b4-a82d-ae23935535dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import scienceplots as scp\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 6)\n",
    "\n",
    "from main import main, parse_args\n",
    "\n",
    "from argparse import Namespace\n",
    "from utils.plotting import plot_change_responses, plot_trial_responses, plot_omission_responses, plot_sequence_response\n",
    "from utils.analysis import process_outputs, get_change_responses, get_omission_responses\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SCRATCH = \"/storage/scratch1/2/asharafeldin3/novelty_encoding_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3555d-bf95-453b-ab80-b4165c46f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib \n",
    "import utils.plotting\n",
    "importlib.reload(utils.plotting)\n",
    "from utils.plotting import plot_change_responses, plot_trial_responses, plot_omission_responses, plot_sequence_response, plot_training_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_files(directory, prefix):\n",
    "    # Ensure directory exists\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"Error: {directory} is not a valid directory.\")\n",
    "        return {}\n",
    "\n",
    "    # Get list of files in directory\n",
    "    files = os.listdir(directory)\n",
    "    # Filter files by prefix and ending with '.pt'\n",
    "    torch_files = [file for file in files if file.startswith(prefix)]\n",
    "\n",
    "    args = None\n",
    "\n",
    "    change_responses = {\"familiar\": {}, \"novel\": {}}\n",
    "    omission_responses = {\"familiar\": {}, \"novel\": {}}\n",
    "    training_progress = {}\n",
    "    for i, file in enumerate(torch_files):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            # Load Torch file\n",
    "            data = torch.load(file_path, map_location='cpu')\n",
    "            # Concatenate tensors along the first axis\n",
    "\n",
    "            if args is None:\n",
    "                args = data['args']\n",
    "\n",
    "            # first for change responses\n",
    "            for key in data[\"change_responses\"][\"familiar\"].keys():\n",
    "                fam_value = data[\"change_responses\"][\"familiar\"][key]\n",
    "                nov_value = data[\"change_responses\"][\"novel\"][key]\n",
    "                if key not in change_responses[\"familiar\"]:\n",
    "                    change_responses[\"familiar\"][key] = fam_value\n",
    "                    change_responses[\"novel\"][key] = nov_value\n",
    "                else:\n",
    "                    change_responses[\"familiar\"][key] = torch.cat([change_responses[\"familiar\"][key], fam_value])\n",
    "                    change_responses[\"novel\"][key] = torch.cat([change_responses[\"novel\"][key], nov_value])\n",
    "            \n",
    "            # now for omission responses\n",
    "            for key in data[\"omission_responses\"][\"familiar\"].keys():\n",
    "                fam_value = data[\"omission_responses\"][\"familiar\"][key]\n",
    "                nov_value = data[\"omission_responses\"][\"novel\"][key]\n",
    "                if key not in omission_responses[\"familiar\"]:\n",
    "                    omission_responses[\"familiar\"][key] = fam_value\n",
    "                    omission_responses[\"novel\"][key] = nov_value\n",
    "                else:\n",
    "                    omission_responses[\"familiar\"][key] = torch.cat([omission_responses[\"familiar\"][key], fam_value])\n",
    "                    omission_responses[\"novel\"][key] = torch.cat([omission_responses[\"novel\"][key], nov_value])\n",
    "            \n",
    "            # finally training progress\n",
    "            for key in data['training_progress'].keys():\n",
    "                if key not in training_progress:\n",
    "                    training_progress[key] = [data['training_progress'][key]]\n",
    "                else:\n",
    "                    training_progress[key] += [data['training_progress'][key]]\n",
    "\n",
    "            print(f\"Loaded {i + 1}/{len(torch_files)} files\", end='\\r')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {str(e)}\")\n",
    "    \n",
    "    training_progress = {k: np.stack(v) for k, v in training_progress.items()}\n",
    "    \n",
    "    return args, change_responses, omission_responses, training_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66f682",
   "metadata": {},
   "source": [
    "### Perception only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc709a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_args, passive_change, passive_omission, passive_progress = load_results_files(f\"{SCRATCH}/results/perception_only/w\", \"perception_only\")\n",
    "passive_args = Namespace(**passive_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e84b74-9dda-41e4-97b7-0435b7eb6b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### plot responses around image change\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "        \n",
    "    passive_change_fig = plt.figure(figsize=(20, 15))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    for i, pop in enumerate(passive_change['familiar'].keys()):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plot_trial_responses(passive_args, ax, passive_change['familiar'][pop], passive_change['novel'][pop], normalize=False)\n",
    "        ax.set_title(f\"{pop}\")\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b98806-549a-41b4-bab7-4c550db6c6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot responses around omissions\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "    \n",
    "    passive_omission_fig = plt.figure(figsize=(20, 15))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    for i, pop in enumerate(passive_omission['familiar'].keys()):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plot_trial_responses(passive_args, ax, passive_omission['familiar'][pop], passive_omission['novel'][pop], trial_mode='omission', normalize=False)\n",
    "        _ = ax.set_title(f\"{pop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae75d77-5f1d-4e60-8570-f600cc4df12c",
   "metadata": {},
   "source": [
    "### Perception with Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1f7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_args, active_change, active_omission, active_progress = load_results_files(f\"./results/perception_action\", \"perception_action\")\n",
    "active_args = Namespace(**active_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot responses around image change\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "        \n",
    "    active_change_fig = plt.figure(figsize=(20, 10))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    for i, pop in enumerate(active_change['familiar'].keys()):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plot_trial_responses(active_args, ax, active_change['familiar'][pop], active_change['novel'][pop], normalize=False)\n",
    "        ax.set_title(f\"{pop}\")\n",
    "        #ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3929afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### plot responses around omissions\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "\n",
    "    active_omission_fig = plt.figure(figsize=(20, 15))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    for i, pop in enumerate(active_omission['familiar'].keys()):\n",
    "        ax = plt.subplot(4, 3, i+1)\n",
    "        plot_trial_responses(active_args, ax, active_omission['familiar'][pop], active_omission['novel'][pop], trial_mode='omission', normalize=False)\n",
    "        _ = ax.set_title(f\"{pop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6a511-01a1-46c4-bbee-b75fd70a95d5",
   "metadata": {},
   "source": [
    "### Raincloud plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3623f9-e6a5-4175-901f-a49a284172a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import raincloud_plot\n",
    "\n",
    "sq = 3\n",
    "\n",
    "exp_ax1 = plt.subplot(1, 2, 1)\n",
    "famt = active_change['familiar']['theta'][:, 3].detach()\n",
    "novt = active_change['novel']['theta'][:, 3].detach()\n",
    "nonlin = lambda x: x.mean(0) #torch.relu(x - .95).mean(0) #(1 - 0.1 * x).mean(-1) \n",
    "print(nonlin(novt).shape)\n",
    "raincloud_plot(exp_ax1, nonlin(famt), nonlin(novt))\n",
    "plt.title('SST (theta)')\n",
    "#plt.ylim([0., 0.65])\n",
    "\n",
    "exp_ax2 = plt.subplot(1, 2, 2)\n",
    "fams = active_change['novel']['sigma_p'][:, 3].detach()\n",
    "novs = active_change['novel']['sigma_p'][:, 9].detach()\n",
    "raincloud_plot(exp_ax2, torch.mean(fams, dim=0), torch.mean(novs, dim=0))\n",
    "plt.title('VIP (sigma_p)')\n",
    "#plt.ylim([0., 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a1ef3-ea9b-4dec-a288-6d365225a031",
   "metadata": {},
   "source": [
    "### Training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6ce2a3-1de0-480c-b8d0-a4e14d934f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dprime = active_progress['temporal_error'].mean(0)\n",
    "plt.plot(dprime, '-ok', linewidth=2.0, markersize=5)\n",
    "plt.plot(np.arange(len(dprime)), np.zeros_like(dprime), '--', label='Chance level')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b47dc-519d-475e-8117-73c9b2c727f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_args.temporal_start = 50\n",
    "active_args.energy_start = 75\n",
    "active_args.value_start = 50\n",
    "\n",
    "_ = plot_training_progress(active_args, active_progress, save_fig=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (projects)",
   "language": "python",
   "name": "projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
