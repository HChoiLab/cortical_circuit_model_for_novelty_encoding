{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66d8690-e0e0-438d-9344-24c26d57c1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed = 2814\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "from utils import data as dutils\n",
    "from utils import stimuli as sutils\n",
    "from utils.data import get_sequences\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "import scienceplots as scp\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from baselines import AdaptationModel\n",
    "from task import fetch_sequences\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 6)\n",
    "\n",
    "EPS = 1e-6\n",
    "PI = torch.acos(torch.zeros(1)).item() * 2\n",
    "\n",
    "SCRATCH = \"./datasets\" #\"/storage/scratch1/2/asharafeldin3\"\n",
    "\n",
    "seed = np.random.randint(1001, 9999)\n",
    "print(f\"seed = {seed}\")\n",
    "\n",
    "# set a random seed \n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338cb5a-7e21-4508-b3d1-0a2e2814b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument parser \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    \"\"\" data paths \"\"\"\n",
    "    parser.add_argument(\"--train_path\", type=str, default=SCRATCH + \"/train\",\n",
    "                        help=\"Path to training (familiar) images\")\n",
    "    parser.add_argument(\"--test_path\", type=str, default=SCRATCH + \"/test\",\n",
    "                        help=\"Path to test (novel) images\")\n",
    "    parser.add_argument(\"--num_train\", type=int, default=40,\n",
    "                        help=\"Number of training images to use\")\n",
    "    parser.add_argument(\"--num_test\", type=int, default=40,\n",
    "                        help=\"Number of test images to use\")\n",
    "\n",
    "    \"\"\" sequence setup \"\"\"\n",
    "    parser.add_argument(\"--image_dim\", type=int, default=8)\n",
    "    parser.add_argument(\"--blank_ts\", type=int, default=10,\n",
    "                        help=\"Number of blank time steps\")\n",
    "    parser.add_argument(\"--img_ts\", type=int, default=5,\n",
    "                        help=\"Number of image time steps\")\n",
    "    parser.add_argument(\"--num_pres\", type=int, default=6,\n",
    "                        help=\"Length of sequence, i.e. number of image presentations\")\n",
    "    parser.add_argument(\"--train_omission_prob\", type=float, default=0.0,\n",
    "                        help=\"Omission probability for familiar sequences\")\n",
    "    parser.add_argument(\"--test_omission_prob\", type=float, default=0.3,\n",
    "                        help=\"Omission probability for novel sequences\")\n",
    "\n",
    "    \"\"\" model parameters \"\"\"\n",
    "    parser.add_argument(\"--latent_dim\", type=float, default=64)\n",
    "    parser.add_argument(\"--h_dim\", type=int, default=128)\n",
    "    parser.add_argument(\"--lambda_kl\", type=float, default=5.0)\n",
    "    parser.add_argument(\"--lambda_energy\", type=float, default=5.0)\n",
    "    parser.add_argument(\"--lambda_reward\", type=float, default=0.1)\n",
    "    parser.add_argument(\"--nonlinearity\", type=str, default=\"relu\")\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda\")\n",
    "\n",
    "    \"\"\" training parameters \"\"\"\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "    parser.add_argument(\"--num_epochs\", type=int, default=200)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "\n",
    "    return parser.parse_known_args()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f19ec2-7339-4d76-99e1-843c7ee1580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for plotting\n",
    "def plot_change_responses(args, ax, responses, label, clr, sem=True):\n",
    "    response_mean = responses.mean([0, -1]).detach()\n",
    "    response_std = responses.mean(-1).std(0).detach() / np.sqrt(responses.shape[0])\n",
    "    \n",
    "    half_blank = args.blank_ts // 2\n",
    "    \n",
    "    ax.axvspan(half_blank, half_blank + args.img_ts, color=\"r\", alpha=0.05)\n",
    "    ax.axvspan(half_blank + args.blank_ts + args.img_ts, half_blank + args.blank_ts + 2 * args.img_ts, color=\"b\", alpha=0.05)\n",
    "    \n",
    "    ax.plot(response_mean.numpy(), label=label, color=clr, linewidth=3.0)\n",
    "    if sem:\n",
    "        ax.fill_between(np.arange(responses.shape[1]),\n",
    "                        response_mean - response_std,\n",
    "                        response_mean + response_std,\n",
    "                        color=clr, alpha=0.25)\n",
    "\n",
    "def plot_omission_responses(args, ax, responses, label, image_clr, trace_clr, sem=True):\n",
    "    response_mean = responses.mean([0, -1]).detach()\n",
    "    response_std = responses.mean(-1).std(0).detach() / np.sqrt(responses.shape[0])\n",
    "    \n",
    "    half_blank = args.blank_ts // 2\n",
    "    \n",
    "    # first image\n",
    "    ax.axvspan(half_blank, half_blank + args.img_ts, color='magenta', alpha=0.05)\n",
    "\n",
    "    # omitted image\n",
    "    ax.axvline(args.blank_ts + half_blank + args.img_ts, linestyle=\"--\", color='magenta', linewidth=2.5)\n",
    "    ax.axvline(args.blank_ts + half_blank + 2 * args.img_ts, linestyle=\"--\", color='magenta', linewidth=2.5)\n",
    "\n",
    "    # last image\n",
    "    ax.axvspan(2 * args.blank_ts + half_blank + 2 * args.img_ts,\n",
    "               2 * args.blank_ts + half_blank + 3 * args.img_ts, color='magenta', alpha=0.05)\n",
    "    \n",
    "    ax.plot(response_mean.numpy(), label=label, color=trace_clr, linewidth=3.0)\n",
    "    if sem:\n",
    "        ax.fill_between(np.arange(responses.shape[1]),\n",
    "                        response_mean - response_std,\n",
    "                        response_mean + response_std,\n",
    "                        color=trace_clr, alpha=0.25)\n",
    "        \n",
    "def raincloud_plot(ax, familiar_responses, novel_responses):\n",
    "\n",
    "    # Create a list of colors for the boxplots based on the number of features you have\n",
    "    boxplots_colors = ['darkorange', 'darkblue']\n",
    "    median_colors = ['orangered', 'navy']\n",
    "\n",
    "    # Boxplot data\n",
    "    data = [familiar_responses, novel_responses]\n",
    "    bp = ax.boxplot(data, patch_artist = True, vert = True, showmeans=True, showfliers=False,\n",
    "                   meanprops={'markersize': 10, 'markerfacecolor': 'darkgreen'})\n",
    "\n",
    "    # Change to the desired color and add transparency\n",
    "    for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_edgecolor(color)\n",
    "        patch.set_alpha(0.35)\n",
    "        patch.set_linewidth(2.0)\n",
    "        patch.set_linestyle('solid')\n",
    "    \n",
    "    for patch, color in zip(bp['medians'], median_colors):\n",
    "        patch.set_color(color)\n",
    "        patch.set_linewidth(2.5)\n",
    "\n",
    "    # Create a list of colors for the violin plots based on the number of features you have\n",
    "    violin_colors = ['orange', 'cornflowerblue']\n",
    "\n",
    "    # Violinplot data\n",
    "    vp = ax.violinplot(data, points=500, \n",
    "                   showmeans=False, showextrema=False, showmedians=False, vert=True)\n",
    "    \n",
    "    for idx, b in enumerate(vp['bodies']):\n",
    "        # Get the center of the plot\n",
    "        m = np.mean(b.get_paths()[0].vertices[:, 0])\n",
    "        # Modify it so we only see the upper half of the violin plot\n",
    "        b.get_paths()[0].vertices[:, 0] = np.clip(b.get_paths()[0].vertices[:, 0], idx+1, idx+2)\n",
    "        # Change to the desired color\n",
    "        b.set_color(violin_colors[idx])\n",
    "        b.set_alpha(0.3)\n",
    "    \n",
    "\n",
    "    # Create a list of colors for the scatter plots based on the number of features you have\n",
    "    scatter_colors = ['darkorange', 'darkblue']\n",
    "\n",
    "    # Scatterplot data\n",
    "    for idx, features in enumerate(data):\n",
    "        # Add jitter effect so the features do not overlap on the y-axis\n",
    "        y = np.full(len(features), idx + .8)\n",
    "        idxs = np.arange(len(y))\n",
    "        out = y.astype(float)\n",
    "        out.flat[idxs] += np.random.uniform(low=-.05, high=.05, size=len(idxs))\n",
    "        y = out\n",
    "        plt.scatter(y, features, s=10, c=scatter_colors[idx])\n",
    "\n",
    "    plt.xticks(np.arange(1,3,1), ['Familiar', 'Novel'])  # Set text labels.\n",
    "    plt.ylabel('Average response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8c4271-0dce-420b-a14f-a7360409306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward_sequence(batch_size, seq_len, seq_ts,\n",
    "                        reward_window=6,\n",
    "                        reward_amount=1.0,\n",
    "                        action_cost=0.5):\n",
    "    # for each sequence, creates a reward sequence with the reward an agent gets if it licks at time t\n",
    "    \n",
    "    reward_seq = torch.ones((batch_size, seq_len), requires_grad=False) * (-action_cost)\n",
    "    for s in range(len(reward_seq)):\n",
    "        \n",
    "        change_time = seq_ts[s]['after'][0][0]\n",
    "        reward_seq[s, change_time:change_time+reward_window] = reward_amount - action_cost\n",
    "    \n",
    "    return reward_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd4809d-436d-4a21-b859-5f3d86ded2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training functions\n",
    "def training_epoch(model, dataloader, epoch, optimizer=None, device='cuda'):\n",
    "    \n",
    "    pbar = tqdm.tqdm(dataloader, unit='batch')\n",
    "    pbar.set_description(f\"Epoch {epoch}\")\n",
    "    \n",
    "    for itr, (Y, labels) in enumerate(pbar):\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        output = model.forward_sequence(Y)\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            output['MSE'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            pbar.set_postfix(mse=output['MSE'].item())\n",
    "\n",
    "def train(model, dataloader, num_epochs=10, device='cuda'):\n",
    "    \n",
    "    optimizer = None #torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        training_epoch(model, dataloader, epoch, optimizer, device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd2ffff-4033-4514-af13-c0c51228b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset object to hold data\n",
    "class SequenceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_tensor, rewards_tensor):\n",
    "        self.x = data_tensor\n",
    "        self.R = rewards_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.R[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f148c22-c24b-40c1-a210-1c477de4617d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './datasetstrain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m args \u001b[38;5;241m=\u001b[39m parse_args()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# train and test sequences\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#args.test_omission_prob = 0.0\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_seqs, train_ts, train_oms, test_seqs, test_ts, test_oms \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m y_dim \u001b[38;5;241m=\u001b[39m train_seqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# train sequences with omissions (for omission analysis)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\abdos\\Documents\\research_code\\cortical_circuit_model_for_novelty_encoding\\task.py:17\u001b[0m, in \u001b[0;36mfetch_sequences\u001b[1;34m(args, seed)\u001b[0m\n\u001b[0;32m     14\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# load the images\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m all_train \u001b[38;5;241m=\u001b[39m dutils\u001b[38;5;241m.\u001b[39mload_images_to_numpy_array(args\u001b[38;5;241m.\u001b[39mtrain_path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     18\u001b[0m all_test \u001b[38;5;241m=\u001b[39m dutils\u001b[38;5;241m.\u001b[39mload_images_to_numpy_array(args\u001b[38;5;241m.\u001b[39mtest_path, grayscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(args\u001b[38;5;241m.\u001b[39mtest_path))) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     19\u001b[0m all_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((all_train, all_test))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './datasetstrain'"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------- TRAINING ------------------------------------------------------- #\n",
    "# parse arguments\n",
    "args = parse_args()\n",
    "\n",
    "# train and test sequences\n",
    "#args.test_omission_prob = 0.0\n",
    "train_seqs, train_ts, train_oms, test_seqs, test_ts, test_oms = fetch_sequences(args)\n",
    "y_dim = train_seqs.shape[-1]\n",
    "\n",
    "# train sequences with omissions (for omission analysis)\n",
    "args.train_omission_prob = args.test_omission_prob\n",
    "train_om_seqs, train_om_ts, train_oms, _, _, _ = fetch_sequences(args)\n",
    "\n",
    "# create reward tensor for train and test sequences\n",
    "R_train = get_reward_sequence(*train_seqs.shape[:2], train_ts, reward_window=args.img_ts+2)\n",
    "R_test = get_reward_sequence(*test_seqs.shape[:2], test_ts, reward_window=args.img_ts+2)\n",
    "R_train_om = get_reward_sequence(*train_seqs.shape[:2], train_om_ts, reward_window=args.img_ts+2)\n",
    "\n",
    "# TODO: should we normalize images to be between 0 and 1?\n",
    "Y_train = torch.Tensor(train_seqs).float().to(args.device)\n",
    "Y_test = torch.Tensor(test_seqs).float()\n",
    "Y_train_om = torch.Tensor(train_om_seqs).float().to(args.device)\n",
    "\n",
    "# create data loaders\n",
    "train_dataset = SequenceDataset(Y_train, R_train)\n",
    "test_dataset = SequenceDataset(Y_test, R_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "# create adaptation model\n",
    "model = AdaptationModel(num_neurons_E=32,\n",
    "                        num_neurons_VIP=32,\n",
    "                        num_neurons_SST=32,\n",
    "                        num_inputs=Y_train.shape[-1],\n",
    "                        tau_E=.3,\n",
    "                        tau_VIP=.3,\n",
    "                        tau_SST=.3,\n",
    "                        tau_A=1.,\n",
    "                        g_E=20.0,\n",
    "                        g_VIP=20.0,\n",
    "                        g_SST=10.0,\n",
    "                        eta=0.00001,\n",
    "                        alpha=0.001,\n",
    "                        dt=0.1,\n",
    "                        hebbian=False,\n",
    "                        device=args.device).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934a11f-7d1d-461d-a82d-9b63493f906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.hebbian:\n",
    "    train(model, train_dataloader, num_epochs=15, device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5605f7-27ab-43ec-9c06-4bf6e57a5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = model.forward_sequence(Y_train.to(args.device))\n",
    "nov = model.forward_sequence(Y_test.to(args.device))\n",
    "fam_om = model.forward_sequence(Y_train_om.to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e60ac-28d6-4b38-b9c6-0787972033ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sequences (familiar)\n",
    "train_seq = 0\n",
    "\n",
    "fig1 = plt.figure(figsize=(15, 10))\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "\n",
    "    ax1 = plt.subplot(3, 1, 1)\n",
    "    ax2 = plt.subplot(3, 1, 2, sharex=ax1)\n",
    "    ax3 = plt.subplot(3, 1, 3, sharex=ax1)\n",
    "    \n",
    "    for bf_on, bf_off in zip(*train_ts[train_seq]['before']):\n",
    "        ax1.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "        ax2.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "        ax3.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "\n",
    "    for af_on, af_off in zip(*train_ts[train_seq]['after']):\n",
    "        ax1.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "        ax2.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "        ax3.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "\n",
    "    ax1.plot(fam['E'][train_seq].mean(-1).cpu().detach().numpy(), c='darkorange', label=\"Familiar\", linewidth=2.0)\n",
    "    ax1.set_title(\"Excitatory (Familiar)\")\n",
    "    ax1.locator_params('x', nbins=4)\n",
    "    ax1.locator_params('y', nbins=2)\n",
    "    \n",
    "    ax2.plot(fam['VIP'][train_seq].mean(-1).cpu().detach().numpy(), c='darkorange', label=\"Familiar\", linewidth=2.0)\n",
    "    ax2.set_title(\"VIP (Familiar)\")\n",
    "    ax2.locator_params('x', nbins=4)\n",
    "    ax2.locator_params('y', nbins=2)\n",
    "    \n",
    "    ax3.plot(fam['SST'][train_seq].mean(-1).cpu().detach().numpy(), c='darkorange', label=\"Familiar\", linewidth=2.0)\n",
    "    ax3.set_xlabel(\"Timestep\")\n",
    "    ax3.set_title(\"SST (Familiar)\")\n",
    "    ax3.locator_params('x', nbins=4)\n",
    "    ax3.locator_params('y', nbins=2)\n",
    "    \n",
    "    \n",
    "    ax1.tick_params('x', which='both', top=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7f1a5-8d69-4545-bf75-b3486f46e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example sequences (novel)\n",
    "test_seq = 1\n",
    "\n",
    "fig1 = plt.figure(figsize=(15, 10))\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "\n",
    "    ax1 = plt.subplot(3, 1, 1)\n",
    "    ax2 = plt.subplot(3, 1, 2, sharex=ax1)\n",
    "    ax3 = plt.subplot(3, 1, 3, sharex=ax1)\n",
    "    \n",
    "    for bf_on, bf_off in zip(*test_ts[test_seq]['before']):\n",
    "        ax1.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "        ax2.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "        ax3.axvspan(bf_on, bf_off, color=\"r\", alpha=0.09)\n",
    "\n",
    "    for af_on, af_off in zip(*test_ts[test_seq]['after']):\n",
    "        ax1.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "        ax2.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "        ax3.axvspan(af_on, af_off, color=\"b\", alpha=0.09)\n",
    "\n",
    "    ax1.plot(nov['E'][test_seq].mean(-1).cpu().detach().numpy(), c='darkblue', label=\"Familiar\", linewidth=2.0)\n",
    "    ax1.set_title(\"Excitatory (Novel)\")\n",
    "    ax1.locator_params('x', nbins=4)\n",
    "    ax1.locator_params('y', nbins=2)\n",
    "    \n",
    "    ax2.plot(nov['VIP'][test_seq].mean(-1).cpu().detach().numpy(), c='darkblue', label=\"Familiar\", linewidth=2.0)\n",
    "    ax2.set_title(\"VIP (Novel)\")\n",
    "    ax2.locator_params('x', nbins=4)\n",
    "    ax2.locator_params('y', nbins=2)\n",
    "    \n",
    "    ax3.plot(nov['SST'][test_seq].mean(-1).cpu().detach().numpy(), c='darkblue', label=\"Familiar\", linewidth=2.0)\n",
    "    ax3.set_xlabel(\"Timestep\")\n",
    "    ax3.set_title(\"SST (Novel)\")\n",
    "    ax3.locator_params('x', nbins=4)\n",
    "    ax3.locator_params('y', nbins=2)\n",
    "    \n",
    "    \n",
    "    ax1.tick_params('x', which='both', top=False, labelbottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5859ca9-65bd-4d36-aabc-a7057cc12d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot responses around image change\n",
    "\n",
    "test_no_om_indcs = np.where(np.array(test_oms) <= 0)[0]\n",
    "num_test_no_omission = len(test_no_om_indcs)\n",
    "\n",
    "half_blank = args.blank_ts // 2\n",
    "trial_dur = 2 * half_blank + args.blank_ts + 2 * args.img_ts + 1\n",
    "\n",
    "e_change_fam = torch.zeros(Y_train.shape[0], trial_dur, fam['E'].shape[-1])\n",
    "e_change_nov = torch.zeros(num_test_no_omission, trial_dur, nov['E'].shape[-1])\n",
    "\n",
    "vip_change_fam = torch.zeros(Y_train.shape[0], trial_dur, fam['VIP'].shape[-1])\n",
    "vip_change_nov = torch.zeros(num_test_no_omission, trial_dur, nov['VIP'].shape[-1])\n",
    "\n",
    "sst_change_fam = torch.zeros(Y_train.shape[0], trial_dur, fam['SST'].shape[-1])\n",
    "sst_change_nov = torch.zeros(num_test_no_omission, trial_dur, nov['SST'].shape[-1])\n",
    "\n",
    "for s in range(Y_train.shape[0]):\n",
    "    start = train_ts[s]['before'][0][-1] - half_blank\n",
    "    end = train_ts[s]['after'][1][0] + half_blank + 1\n",
    "    e_change_fam[s] = fam['E'][s, start:end, :]\n",
    "    vip_change_fam[s] = fam['VIP'][s, start:end, :]\n",
    "    sst_change_fam[s] = fam['SST'][s, start:end, :]\n",
    "    \n",
    "for si in range(num_test_no_omission):\n",
    "    s = test_no_om_indcs[si]\n",
    "    start = test_ts[s]['before'][0][-1] - half_blank\n",
    "    end = test_ts[s]['after'][1][0] + half_blank + 1\n",
    "    e_change_nov[si] = nov['E'][s, start:end, :]\n",
    "    vip_change_nov[si] = nov['VIP'][s, start:end, :]\n",
    "    sst_change_nov[si] = nov['SST'][s, start:end, :]\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "\n",
    "    fig3 = plt.figure(figsize=(20, 5))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "    plot_change_responses(args, ax1, e_change_fam, \"Familiar\", \"darkorange\")\n",
    "    plot_change_responses(args, ax1, e_change_nov, \"Novel\", \"darkblue\")\n",
    "    ax1.set_title(\"E\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    plot_change_responses(args, ax2, vip_change_fam, \"Familiar\", \"darkorange\")\n",
    "    plot_change_responses(args, ax2, vip_change_nov, \"Novel\", \"darkblue\")\n",
    "    ax2.set_title(\"VIP\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    plot_change_responses(args, ax3, sst_change_fam, \"Familiar\", \"darkorange\")\n",
    "    plot_change_responses(args, ax3, sst_change_nov, \"Novel\", \"darkblue\")\n",
    "    ax3.set_title(\"SST\")\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1cd8f0-1cb9-4fca-98bd-b15b9e834f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot omission response\n",
    "\n",
    "test_om_indcs = np.where(np.array(test_oms) > 0)[0]\n",
    "train_om_indcs = np.where(np.array(train_oms) > 0)[0]\n",
    "\n",
    "om_trial_dur = 2 * args.blank_ts + 2 * (args.blank_ts // 2) + 3 * args.img_ts\n",
    "\n",
    "e_fam_om = torch.zeros(len(train_om_indcs), om_trial_dur, fam_om['E'].shape[-1])\n",
    "vip_fam_om = torch.zeros(len(train_om_indcs), om_trial_dur, fam_om['VIP'].shape[-1])\n",
    "sst_fam_om = torch.zeros(len(train_om_indcs), om_trial_dur, fam_om['SST'].shape[-1])\n",
    "\n",
    "e_nov_om = torch.zeros(len(test_om_indcs), om_trial_dur, nov['E'].shape[-1])\n",
    "vip_nov_om = torch.zeros(len(test_om_indcs), om_trial_dur, nov['VIP'].shape[-1])\n",
    "sst_nov_om = torch.zeros(len(test_om_indcs), om_trial_dur, nov['SST'].shape[-1])\n",
    "\n",
    "for si in range(len(train_om_indcs)):\n",
    "\n",
    "    s = train_om_indcs[si]\n",
    "    om_ind = train_oms[s]\n",
    "    start = om_ind - (args.blank_ts + args.blank_ts // 2 + args.img_ts)\n",
    "    end = om_ind + (args.blank_ts + args.blank_ts // 2 + args.img_ts)\n",
    "    end = min(end, fam_om['E'].shape[1])\n",
    "    dur = end - start\n",
    "\n",
    "    e_fam_om[si, :dur] = fam_om['E'][s, start:end]\n",
    "    vip_fam_om[si, :dur] = fam_om['VIP'][s, start:end]\n",
    "    sst_fam_om[si, :dur] = fam_om['SST'][s, start:end]\n",
    "\n",
    "\n",
    "for si in range(len(test_om_indcs)):\n",
    "\n",
    "    s = test_om_indcs[si]\n",
    "    om_ind = test_oms[s]\n",
    "    start = om_ind - (args.blank_ts + args.blank_ts // 2 + args.img_ts)\n",
    "    end = om_ind + (args.blank_ts + args.blank_ts // 2 + args.img_ts)\n",
    "    end = min(end, nov['E'].shape[1])\n",
    "    dur = end - start\n",
    "\n",
    "    e_nov_om[si, :dur] = nov['E'][s, start:end]\n",
    "    vip_nov_om[si, :dur] = nov['VIP'][s, start:end]\n",
    "    sst_nov_om[si, :dur] = nov['SST'][s, start:end]\n",
    "\n",
    "\n",
    "with plt.style.context(['nature', 'notebook']):\n",
    "\n",
    "    fig4 = plt.figure(figsize=(20, 5))\n",
    "    plt.tight_layout(pad=10, h_pad=5)\n",
    "\n",
    "    ax1 = plt.subplot(1, 3, 1)\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "    \n",
    "    plot_omission_responses(args, ax1, e_nov_om, \"Novel\", trace_clr=\"darkblue\", image_clr=\"magenta\", sem=True)\n",
    "    plot_omission_responses(args, ax1, e_fam_om, \"Familiar\", trace_clr=\"darkorange\", image_clr=\"magenta\", sem=True)\n",
    "    ax1.set_title(\"E\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    plot_omission_responses(args, ax2, vip_nov_om, \"Novel\", trace_clr=\"darkblue\", image_clr=\"magenta\", sem=True)\n",
    "    plot_omission_responses(args, ax2, vip_fam_om, \"Familiar\", trace_clr=\"darkorange\", image_clr=\"magenta\", sem=True)\n",
    "    ax2.set_title(\"VIP\")\n",
    "    ax2.legend()\n",
    "    \n",
    "    plot_omission_responses(args, ax3, sst_nov_om, \"Novel\", trace_clr=\"darkblue\", image_clr=\"magenta\", sem=True)\n",
    "    plot_omission_responses(args, ax3, sst_fam_om, \"Familiar\", trace_clr=\"darkorange\", image_clr=\"magenta\", sem=True)\n",
    "    ax3.set_title(\"SST\")\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9849e-83e9-4e23-8f37-d15a110436ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.E_to_VIP.weight.data.cpu().detach().numpy())\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
